import pandas as pd
import numpy as np
from scipy import stats
from statsmodels.tsa.stattools import coint
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import itertools
from typing import List, Tuple, Dict
import warnings
warnings.filterwarnings('ignore')

class PairFinder:
    """
    í˜ì–´ íŠ¸ë ˆì´ë”© ê°€ëŠ¥í•œ ì¢…ëª© ìŒì„ ì°¾ëŠ” í´ë˜ìŠ¤
    ìƒê´€ê´€ê³„ ë¶„ì„ê³¼ ê³µì ë¶„ ê²€ì •ì„ í†µí•´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í˜ì–´ë¥¼ ì„ ë³„
    """
    
    def __init__(self, correlation_threshold=0.8, cointegration_pvalue=0.05):
        """
        ì´ˆê¸°í™”
        
        Args:
            correlation_threshold (float): ìƒê´€ê³„ìˆ˜ ì„ê³„ê°’ (0.5-0.95)
            cointegration_pvalue (float): ê³µì ë¶„ ê²€ì • p-value ì„ê³„ê°’ (0.01-0.1)
        """
        self.correlation_threshold = correlation_threshold
        self.cointegration_pvalue = cointegration_pvalue
        
    def find_pairs(self, price_data: pd.DataFrame) -> pd.DataFrame:
        """
        ì£¼ì–´ì§„ ê°€ê²© ë°ì´í„°ì—ì„œ í˜ì–´ íŠ¸ë ˆì´ë”© ê°€ëŠ¥í•œ ì¢…ëª© ìŒì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            price_data (pd.DataFrame): ì¢…ëª©ë³„ ê°€ê²© ë°ì´í„° (ì»¬ëŸ¼: ì¢…ëª©ì½”ë“œ, ì¸ë±ìŠ¤: ë‚ ì§œ)
            
        Returns:
            pd.DataFrame: ë°œê²¬ëœ í˜ì–´ ì •ë³´ (Stock1, Stock2, Correlation, Cointegration_PValue ë“±)
        """
        
        if price_data.empty or len(price_data.columns) < 2:
            return pd.DataFrame()
        
        print(f"ğŸ“Š {len(price_data.columns)}ê°œ ì¢…ëª©ì—ì„œ í˜ì–´ë¥¼ ì°¾ëŠ” ì¤‘...")
        
        # 1ë‹¨ê³„: ìƒê´€ê´€ê³„ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
        high_corr_pairs = self._find_high_correlation_pairs(price_data)
        
        if not high_corr_pairs:
            print("âš ï¸ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ í˜ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        print(f"ğŸ” {len(high_corr_pairs)}ê°œì˜ ë†’ì€ ìƒê´€ê´€ê³„ í˜ì–´ ë°œê²¬")
        
        # 2ë‹¨ê³„: ê³µì ë¶„ ê²€ì •
        cointegrated_pairs = self._test_cointegration(price_data, high_corr_pairs)
        
        if not cointegrated_pairs:
            print("âš ï¸ ê³µì ë¶„ ê´€ê³„ë¥¼ ê°€ì§„ í˜ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        print(f"âœ… {len(cointegrated_pairs)}ê°œì˜ ê³µì ë¶„ í˜ì–´ ë°œê²¬")
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        pairs_df = pd.DataFrame(cointegrated_pairs)
        
        # ì •ë ¬ ë° ì •ë¦¬
        pairs_df = pairs_df.sort_values(['Cointegration_PValue', 'Correlation'], 
                                      ascending=[True, False]).reset_index(drop=True)
        
        return pairs_df
    
    def _find_high_correlation_pairs(self, price_data: pd.DataFrame) -> List[Tuple[str, str, float]]:
        """
        ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ì¢…ëª© ìŒì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            price_data (pd.DataFrame): ê°€ê²© ë°ì´í„°
            
        Returns:
            List[Tuple]: (stock1, stock2, correlation) í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        """
        
        # ë¡œê·¸ ìˆ˜ìµë¥  ê³„ì‚° (ìƒê´€ê´€ê³„ ë¶„ì„ìš©)
        log_returns = np.log(price_data / price_data.shift(1)).dropna()
        
        if log_returns.empty:
            return []
        
        # ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°
        correlation_matrix = log_returns.corr()
        
        high_corr_pairs = []
        symbols = correlation_matrix.columns
        
        # ìƒì‚¼ê°í–‰ë ¬ë§Œ ê²€ì‚¬ (ì¤‘ë³µ ì œê±°)
        for i in range(len(symbols)):
            for j in range(i + 1, len(symbols)):
                correlation = correlation_matrix.iloc[i, j]
                
                # ìœ íš¨í•œ ìƒê´€ê³„ìˆ˜ì´ê³  ì„ê³„ê°’ì„ ë„˜ëŠ” ê²½ìš°
                if (not np.isnan(correlation) and 
                    abs(correlation) >= self.correlation_threshold):
                    
                    high_corr_pairs.append((symbols[i], symbols[j], correlation))
        
        return high_corr_pairs
    
    def _test_cointegration(self, price_data: pd.DataFrame, 
                          candidate_pairs: List[Tuple[str, str, float]]) -> List[Dict]:
        """
        í›„ë³´ í˜ì–´ë“¤ì— ëŒ€í•´ ê³µì ë¶„ ê²€ì •ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            price_data (pd.DataFrame): ê°€ê²© ë°ì´í„°
            candidate_pairs (List): í›„ë³´ í˜ì–´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[Dict]: ê³µì ë¶„ ê´€ê³„ê°€ ìˆëŠ” í˜ì–´ë“¤ì˜ ìƒì„¸ ì •ë³´
        """
        
        cointegrated_pairs = []
        
        for i, (stock1, stock2, correlation) in enumerate(candidate_pairs):
            if i % 10 == 0:
                print(f"ê³µì ë¶„ ê²€ì • ì§„í–‰ë¥ : {i}/{len(candidate_pairs)}")
            
            try:
                # ê°€ê²© ë°ì´í„° ì¶”ì¶œ
                s1_prices = price_data[stock1].dropna()
                s2_prices = price_data[stock2].dropna()
                
                # ê³µí†µ ê¸°ê°„ ë°ì´í„°ë§Œ ì‚¬ìš©
                common_dates = s1_prices.index.intersection(s2_prices.index)
                if len(common_dates) < 30:  # ìµœì†Œ 30ì¼ ë°ì´í„° í•„ìš”
                    continue
                
                s1_common = s1_prices[common_dates]
                s2_common = s2_prices[common_dates]
                
                # Engle-Granger ê³µì ë¶„ ê²€ì •
                coint_result = self._engle_granger_test(s1_common, s2_common)
                
                # Johansen ê³µì ë¶„ ê²€ì • (ë” ì •í™•)
                johansen_result = self._johansen_test(s1_common, s2_common)
                
                # ë‘ ê²€ì • ì¤‘ í•˜ë‚˜ë¼ë„ í†µê³¼í•˜ë©´ ê³µì ë¶„ìœ¼ë¡œ íŒë‹¨
                is_cointegrated = (coint_result['p_value'] < self.cointegration_pvalue or
                                 johansen_result['is_cointegrated'])
                
                if is_cointegrated:
                    # ì¶”ê°€ í†µê³„ ì •ë³´ ê³„ì‚°
                    spread_stats = self._calculate_spread_statistics(s1_common, s2_common)
                    
                    pair_info = {
                        'Stock1': stock1,
                        'Stock2': stock2,
                        'Correlation': correlation,
                        'Cointegration_PValue': min(coint_result['p_value'], 
                                                  johansen_result.get('p_value', 1.0)),
                        'EG_PValue': coint_result['p_value'],
                        'EG_Statistic': coint_result['statistic'],
                        'Johansen_Cointegrated': johansen_result['is_cointegrated'],
                        'Spread_Mean': spread_stats['mean'],
                        'Spread_Std': spread_stats['std'],
                        'Spread_StationarityScore': spread_stats['stationarity_score'],
                        'HalfLife': spread_stats['half_life']
                    }
                    
                    cointegrated_pairs.append(pair_info)
                    
            except Exception as e:
                print(f"ê³µì ë¶„ ê²€ì • ì˜¤ë¥˜ ({stock1}-{stock2}): {e}")
                continue
        
        return cointegrated_pairs
    
    def _engle_granger_test(self, s1: pd.Series, s2: pd.Series) -> Dict:
        """
        Engle-Granger ê³µì ë¶„ ê²€ì •ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            s1, s2 (pd.Series): ë‘ ì‹œê³„ì—´ ë°ì´í„°
            
        Returns:
            Dict: ê²€ì • ê²°ê³¼ (statistic, p_value)
        """
        try:
            # ê³µì ë¶„ ê²€ì • ì‹¤í–‰
            score, p_value, _ = coint(s1, s2)
            
            return {
                'statistic': score,
                'p_value': p_value,
                'is_cointegrated': p_value < self.cointegration_pvalue
            }
        except:
            return {
                'statistic': np.nan,
                'p_value': 1.0,
                'is_cointegrated': False
            }
    
    def _johansen_test(self, s1: pd.Series, s2: pd.Series) -> Dict:
        """
        Johansen ê³µì ë¶„ ê²€ì •ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            s1, s2 (pd.Series): ë‘ ì‹œê³„ì—´ ë°ì´í„°
            
        Returns:
            Dict: ê²€ì • ê²°ê³¼
        """
        try:
            # ë¡œê·¸ ë³€í™˜
            log_data = np.log(np.column_stack([s1, s2]))
            
            # Johansen ê²€ì • ì‹¤í–‰
            result = coint_johansen(log_data, det_order=0, k_ar_diff=1)
            
            # trace í†µê³„ëŸ‰ê³¼ ì„ê³„ê°’ ë¹„êµ (5% ìœ ì˜ìˆ˜ì¤€)
            trace_stat = result.lr1[0]  # ì²« ë²ˆì§¸ trace í†µê³„ëŸ‰
            critical_value = result.cvt[0, 1]  # 5% ì„ê³„ê°’
            
            is_cointegrated = trace_stat > critical_value
            
            return {
                'trace_statistic': trace_stat,
                'critical_value': critical_value,
                'is_cointegrated': is_cointegrated,
                'p_value': 0.05 if not is_cointegrated else 0.01  # ê·¼ì‚¬ì¹˜
            }
        except:
            return {
                'trace_statistic': np.nan,
                'critical_value': np.nan,
                'is_cointegrated': False,
                'p_value': 1.0
            }
    
    def _calculate_spread_statistics(self, s1: pd.Series, s2: pd.Series) -> Dict:
        """
        ìŠ¤í”„ë ˆë“œì˜ í†µê³„ì  íŠ¹ì„±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            s1, s2 (pd.Series): ë‘ ì‹œê³„ì—´ ë°ì´í„°
            
        Returns:
            Dict: ìŠ¤í”„ë ˆë“œ í†µê³„ ì •ë³´
        """
        try:
            # ë¡œê·¸ ê°€ê²©ìœ¼ë¡œ ë³€í™˜
            log_s1 = np.log(s1)
            log_s2 = np.log(s2)
            
            # íšŒê·€ë¶„ì„ìœ¼ë¡œ í—¤ì§€ ë¹„ìœ¨ ê³„ì‚°
            from sklearn.linear_model import LinearRegression
            model = LinearRegression()
            model.fit(log_s2.values.reshape(-1, 1), log_s1.values)
            hedge_ratio = model.coef_[0]
            
            # ìŠ¤í”„ë ˆë“œ ê³„ì‚°
            spread = log_s1 - hedge_ratio * log_s2
            
            # ê¸°ë³¸ í†µê³„ëŸ‰
            spread_mean = spread.mean()
            spread_std = spread.std()
            
            # í‰ê·  íšŒê·€ ë°˜ê°ê¸° ê³„ì‚°
            half_life = self._calculate_half_life(spread)
            
            # ì •ìƒì„± ì ìˆ˜ (ADF ê²€ì • ê¸°ë°˜)
            stationarity_score = self._calculate_stationarity_score(spread)
            
            return {
                'mean': spread_mean,
                'std': spread_std,
                'hedge_ratio': hedge_ratio,
                'half_life': half_life,
                'stationarity_score': stationarity_score
            }
        except:
            return {
                'mean': np.nan,
                'std': np.nan,
                'hedge_ratio': 1.0,
                'half_life': np.nan,
                'stationarity_score': 0.0
            }
    
    def _calculate_half_life(self, spread: pd.Series) -> float:
        """
        í‰ê·  íšŒê·€ì˜ ë°˜ê°ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            spread (pd.Series): ìŠ¤í”„ë ˆë“œ ì‹œê³„ì—´
            
        Returns:
            float: ë°˜ê°ê¸° (ì¼ ë‹¨ìœ„)
        """
        try:
            from sklearn.linear_model import LinearRegression
            
            # ìŠ¤í”„ë ˆë“œ ì°¨ë¶„ ê³„ì‚°
            spread_lag = spread.shift(1).dropna()
            spread_diff = spread.diff().dropna()
            
            # ê³µí†µ ì¸ë±ìŠ¤
            common_idx = spread_lag.index.intersection(spread_diff.index)
            spread_lag = spread_lag[common_idx]
            spread_diff = spread_diff[common_idx]
            
            if len(spread_lag) < 10:
                return np.nan
            
            # íšŒê·€ë¶„ì„: Î”spread = Î± + Î² * spread_{t-1}
            model = LinearRegression()
            model.fit(spread_lag.values.reshape(-1, 1), spread_diff.values)
            beta = model.coef_[0]
            
            # ë°˜ê°ê¸° = ln(2) / (-Î²)
            if beta < 0:
                half_life = np.log(2) / (-beta)
                return min(half_life, 252)  # ìµœëŒ€ 1ë…„ìœ¼ë¡œ ì œí•œ
            else:
                return np.nan
        except:
            return np.nan
    
    def _calculate_stationarity_score(self, spread: pd.Series) -> float:
        """
        ìŠ¤í”„ë ˆë“œì˜ ì •ìƒì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (0-1 ë²”ìœ„).
        
        Args:
            spread (pd.Series): ìŠ¤í”„ë ˆë“œ ì‹œê³„ì—´
            
        Returns:
            float: ì •ìƒì„± ì ìˆ˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •ìƒ)
        """
        try:
            from statsmodels.tsa.stattools import adfuller
            
            # ADF ê²€ì •
            adf_result = adfuller(spread.dropna())
            adf_pvalue = adf_result[1]
            
            # p-valueë¥¼ 0-1 ì ìˆ˜ë¡œ ë³€í™˜ (p-valueê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            stationarity_score = max(0, 1 - adf_pvalue)
            
            return stationarity_score
        except:
            return 0.0
    
    def filter_pairs_by_criteria(self, pairs_df: pd.DataFrame, 
                                min_correlation=None,
                                max_pvalue=None,
                                min_stationarity=None,
                                max_half_life=None) -> pd.DataFrame:
        """
        ì¶”ê°€ ê¸°ì¤€ìœ¼ë¡œ í˜ì–´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
        
        Args:
            pairs_df (pd.DataFrame): í˜ì–´ ë°ì´í„°í”„ë ˆì„
            min_correlation (float): ìµœì†Œ ìƒê´€ê³„ìˆ˜
            max_pvalue (float): ìµœëŒ€ p-value
            min_stationarity (float): ìµœì†Œ ì •ìƒì„± ì ìˆ˜
            max_half_life (float): ìµœëŒ€ ë°˜ê°ê¸°
            
        Returns:
            pd.DataFrame: í•„í„°ë§ëœ í˜ì–´ ë°ì´í„°í”„ë ˆì„
        """
        filtered_df = pairs_df.copy()
        
        if min_correlation is not None:
            filtered_df = filtered_df[abs(filtered_df['Correlation']) >= min_correlation]
        
        if max_pvalue is not None:
            filtered_df = filtered_df[filtered_df['Cointegration_PValue'] <= max_pvalue]
        
        if min_stationarity is not None and 'Spread_StationarityScore' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['Spread_StationarityScore'] >= min_stationarity]
        
        if max_half_life is not None and 'HalfLife' in filtered_df.columns:
            filtered_df = filtered_df[
                (filtered_df['HalfLife'] <= max_half_life) | 
                (filtered_df['HalfLife'].isna())
            ]
        
        return filtered_df.reset_index(drop=True)
    
    def get_pair_summary(self, pairs_df: pd.DataFrame) -> Dict:
        """
        í˜ì–´ ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        Args:
            pairs_df (pd.DataFrame): í˜ì–´ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            Dict: ìš”ì•½ í†µê³„
        """
        if pairs_df.empty:
            return {}
        
        summary = {
            'total_pairs': len(pairs_df),
            'avg_correlation': pairs_df['Correlation'].mean(),
            'avg_pvalue': pairs_df['Cointegration_PValue'].mean(),
            'correlation_range': (pairs_df['Correlation'].min(), pairs_df['Correlation'].max()),
            'pvalue_range': (pairs_df['Cointegration_PValue'].min(), pairs_df['Cointegration_PValue'].max())
        }
        
        if 'HalfLife' in pairs_df.columns:
            valid_half_life = pairs_df['HalfLife'].dropna()
            if not valid_half_life.empty:
                summary['avg_half_life'] = valid_half_life.mean()
                summary['half_life_range'] = (valid_half_life.min(), valid_half_life.max())
        
        if 'Spread_StationarityScore' in pairs_df.columns:
            summary['avg_stationarity'] = pairs_df['Spread_StationarityScore'].mean()
        
        return summary
